# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

version=0.0.0
environment=Localhost

server.port=7123
spring.web.resources.static-locations=classpath:/ui/
logging.file.path=logs
logging.file.name=${logging.file.path}/app.log

# Spring management endpoints settings
management.endpoints.web.base-path=/admin
management.endpoints.jmx.exposure.exclude=*
management.endpoints.web.exposure.include=*

javamelody.management-endpoint-monitoring-enabled=true

management.endpoint.health.show-details=always
health.databaseConnection.timeoutMillis=120000
health.yarnConnection.testEndpoint=/cluster/cluster

# How will users authenticate. Available options: inmemory, ldap
auth.mechanism=inmemory
auth.admin.role=ROLE_ADMIN

auth.inmemory.user=hyperdriver-user
auth.inmemory.password=hyperdriver-password

auth.inmemory.admin.user=hyperdriver-user-admin
auth.inmemory.admin.password=hyperdriver-password-admin

#
#auth.ldap.search.base=DC=corp,DC=dsarena,DC=com
#auth.ldap.search.filter=(| (sAMAccountName={0}) (altSecurityIdentities={0}) (mail={0}))
#auth.ad.domain=CORP.DSARENA.COM
#auth.ad.server=ldaps://corp.dsarena.com

appUniqueId=b19329fa-5add-4d57-b6d8-2698d78234dc

application.maximumNumberOfWorkflowsInBulkRun=10

# Core properties.
# How many threads to use for each part of the "scheduler".
# Heart beat interval in milliseconds.
scheduler.autostart=false
scheduler.thread.pool.size=10
scheduler.sensors.thread.pool.size=20
scheduler.executors.thread.pool.size=30
scheduler.jobs.parallel.number=100
scheduler.heart.beat=5000
scheduler.lag.threshold=20000
scheduler.sensors.changedSensorsChunkQuerySize=100

#Shell executor properties.
shellExecutor.executablesFolder=/

#Kafka sensor properties.
kafkaSource.group.id.prefix=hyper_drive
kafkaSource.properties.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafkaSource.properties.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafkaSource.poll.duration=500
kafkaSource.properties.max.poll.records=3
kafkaSource.connectionTimeoutMillis=10000

#Recurring sensor properties.
recurringSensor.maxJobsPerDuration=1000
recurringSensor.duration=1h

#Spark yarn sink properties. Properties used to deploy and run Spark job in Yarn.
spark.submitApi=yarn
sparkYarnSink.hadoopResourceManagerUrlBase=http://localhost:8088
sparkYarnSink.hadoopConfDir=/usr/local/Cellar/hadoop/3.3.1/libexec/etc/hadoop
sparkYarnSink.sparkHome=/Users/ABJBA4J/Desktop/spark-2.4.8-bin-hadoop2.7
sparkYarnSink.master=yarn
sparkYarnSink.submitTimeout=120000
sparkYarnSink.additionalConfs.spark.driver.memory=1g
sparkYarnSink.additionalConfs.spark.executor.instances=1
sparkYarnSink.additionalConfs.spark.executor.cores=1
sparkYarnSink.additionalConfs.spark.executor.memory=1g
sparkYarnSink.executablesFolder=/
sparkYarnSink.userUsedToKillJob=Jozef

#spark.emr.clusterId=123123
#spark.emr.filesToDeploy=asdasd
#spark.emr.additionalConfs=asdasd

#Postgresql properties for connection to trigger metastore
db.driver=net.bull.javamelody.JdbcDriver
db.url=jdbc:postgresql://localhost:5432/hyperdriver?driver=org.postgresql.Driver
db.keepAliveConnection=true
db.connectionPool=HikariCP
db.numThreads=4

db.skip.liquibase=false
spring.liquibase.change-log=classpath:/db_scripts/liquibase/db.changelog.yml

notification.enabled=true
notification.sender.address=Hyperdrive Notifications <noreply@absa.co.za>
spring.mail.host=mail.absa.co.za
spring.mail.port=25
