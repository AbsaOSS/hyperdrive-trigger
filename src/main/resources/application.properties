#
# Copyright 2018 ABSA Group Limited
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

version=@project.version@
environment=Cloud

server.port=7123
spring.resources.static-locations=classpath:/ui/
logging.path=logs
logging.file=${logging.path}/app.log

# Spring management endpoints settings
management.endpoints.web.base-path=/admin
management.endpoints.jmx.exposure.exclude=*
management.endpoints.web.exposure.include=*

javamelody.management-endpoint-monitoring-enabled=true
# How will users authenticate. Available options: inmemory, ldap
auth.mechanism=inmemory
# INMEMORY authentication: username and password defined here will be used for authentication.
auth.inmemory.user=user
auth.inmemory.password=password
# LDAP authentication: props template that has to be defined in case of LDAP authentication
#auth.ad.domain=
#auth.ad.server=
#auth.ldap.search.base=
#auth.ldap.search.filter=

#auth.mechanism=ldap
#auth.ldap.search.base=DC=corp,DC=dsarena,DC=com
#auth.ldap.search.filter=(| (sAMAccountName={0}) (altSecurityIdentities={0}) (mail={0}))
#auth.ad.domain=CLOUDAD.DSARENA.COM
#auth.ad.server=ldaps://zapsdcdcg0002.corp.dsarena.com
#
#appUniqueId=432b6572-fd08-48a1-902c-920b3f7k888

# Core properties.
# How many threads to use for each part of the "scheduler".
# Heart beat interval in milliseconds.
scheduler.thread.pool.size=10
scheduler.sensors.thread.pool.size=20
scheduler.executors.thread.pool.size=30
scheduler.jobs.parallel.number=100
scheduler.heart.beat=5000
scheduler.lag.threshold=20000

#Kafka sensor properties.
kafkaSource.group.id=hyper_drive_${appUniqueId}
kafkaSource.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafkaSource.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafkaSource.poll.duration=500
kafkaSource.max.poll.records=3
kafkaSource.properties.enable.auto.commit=false
kafkaSource.properties.auto.offset.reset=latest
kafkaSource.properties.security.protocol=SASL_PLAINTEXT
kafkaSource.properties.ssl.truststore.location=/hyperdrive/hyperdrive-uat-truststore.jks
kafkaSource.properties.ssl.truststore.password=hyperdrive
kafkaSource.properties.ssl.keystore.location=/hyperdrive/hyperdrive-uat-keystore.jks
kafkaSource.properties.ssl.keystore.password=hyperdrive
kafkaSource.properties.ssl.key.password=hyperdrive
kafkaSource.properties.sasl.kerberos.service.name=kafka
kafkaSource.properties.sasl.mechanism=GSSAPI
kafkaSource.properties.sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required doNotPrompt=false useKeyTab=true storeKey=true useTicketCache=false keyTab=\"/hyperdrive/svc-dehdlza-hypert.keytab\" serviceName=\"kafka\" principal=\"svc-dehdlza-hypert@CORP.DSARENA.COM\";
#kafkaSource.properties.sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required doNotPrompt=false useKeyTab=true storeKey=true useTicketCache=false keyTab="/hyperdriveVolume/svc-dehdlza-hypert.keytab" serviceName="kafka" principal="svc-dehdlza-hypert@CORP.DSARENA.COM";
#kafkaSource.properties.client.dns.lookup=resolve_canonical_bootstrap_servers_only

#Spark yarn sink properties. Properties used to deploy and run Spark job in Yarn.
#sparkYarnSink.hadoopResourceManagerUrlBase=http://20.0.11.79:8088
sparkYarnSink.hadoopResourceManagerUrlBase=http://ip-20-0-11-79.eu-west-1.compute.internal:8088
sparkYarnSink.hadoopConfDir=/opt/hadoop/etc/hadoop
sparkYarnSink.sparkHome=/opt/spark
sparkYarnSink.master=yarn
sparkYarnSink.submitTimeout=160000
sparkYarnSink.filesToDeploy=/hyperdrive/svc-dehdlza-hypert.keytab#svc-dehdlza-hypert.keytab,/hyperdrive/hyper_jaas.conf#hyper_jaas.conf,/hyperdrive/hyperdrive-uat-truststore.jks#hyperdrive-uat-truststore.jks,/hyperdrive/hyperdrive-uat-keystore.jks#hyperdrive-uat-keystore.jks,/hyperdrive/krb5.conf#krb5.conf
sparkYarnSink.additionalConfs.spark.ui.port=2002
sparkYarnSink.additionalConfs.spark.executor.extraJavaOptions=-Djava.security.auth.login.config==hyper_jaas.conf -Djavax.net.ssl.trustStore=hyperdrive-uat-truststore.jks -Djavax.net.ssl.keyStore=hyperdrive-uat-keystore.jks -Djavax.net.ssl.trustStorePassword=hyperdrive -Djavax.net.ssl.keyStorePassword=hyperdrive -Djavax.net.ssl.password=hyperdrive -Dsun.security.krb5.debug=true -Djava.security.krb5.conf=krb5.conf
sparkYarnSink.additionalConfs.spark.driver.extraJavaOptions=-Djava.security.auth.login.config==hyper_jaas.conf -Djavax.net.ssl.trustStore=hyperdrive-uat-truststore.jks -Djavax.net.ssl.keyStore=hyperdrive-uat-keystore.jks -Djavax.net.ssl.trustStorePassword=hyperdrive -Djavax.net.ssl.keyStorePassword=hyperdrive -Djavax.net.ssl.password=hyperdrive -Dsun.security.krb5.debug=true -Djava.security.krb5.conf=krb5.conf
sparkYarnSink.additionalConfs.spark.driver.memory=2g
sparkYarnSink.additionalConfs.spark.executor.instances=2
sparkYarnSink.additionalConfs.spark.executor.cores=2
sparkYarnSink.additionalConfs.spark.executor.memory=2g
sparkYarnSink.additionalConfs.spark.yarn.keytab=/hyperdrive/svc-dehdlza-hypert-for-yarn.keytab
sparkYarnSink.additionalConfs.spark.yarn.principal=svc-dehdlza-hypert@CORP.DSARENA.COM
sparkYarnSink.additionalConfs.spark.shuffle.service.enabled=true
sparkYarnSink.additionalConfs.spark.dynamicAllocation.enabled=true

#Postgresql properties for connection to trigger metastore

db.driver=net.bull.javamelody.JdbcDriver
db.url=jdbc:postgresql://euw1devbigdatarnddb-identifier.cluster-cvtpppg2qioh.eu-west-1.rds.amazonaws.com:5432/hyperdrive?driver=org.postgresql.Driver
db.user=hyperdrive
db.password=sTfHwYjsQ7KyR4Qk
db.keepAliveConnection=true
db.connectionPool=HikariCP
db.numThreads=4

db.skip.liquibase=false
spring.liquibase.change-log=classpath:/db_scripts/liquibase/db.changelog.yml
