2020-05-12 10:46:16,210 INFO scala.App$class [main] Starting App.class on Seneles-MBP with PID 49603 (/Users/sonboy/.m2/repository/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar started by sonboy in /Users/sonboy/AbsaOSS/hyperdrive-trigger)
2020-05-12 10:46:16,219 INFO scala.App$class [main] No active profile set, falling back to default profiles: default
2020-05-12 10:46:16,282 INFO org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext [main] Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@76ed1b7c: startup date [Tue May 12 10:46:16 SAST 2020]; root of context hierarchy
2020-05-12 10:46:18,471 INFO org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor [main] JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2020-05-12 10:46:19,007 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat initialized with port(s): 7123 (http)
2020-05-12 10:46:19,027 INFO org.apache.coyote.http11.Http11NioProtocol [main] Initializing ProtocolHandler ["http-nio-7123"]
2020-05-12 10:46:19,040 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2020-05-12 10:46:19,040 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet Engine: Apache Tomcat/8.5.28
2020-05-12 10:46:19,051 INFO org.apache.catalina.core.AprLifecycleListener [localhost-startStop-1] The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/Users/sonboy/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.]
2020-05-12 10:46:19,238 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [localhost-startStop-1] Initializing Spring embedded WebApplicationContext
2020-05-12 10:46:19,238 INFO org.springframework.web.context.ContextLoader [localhost-startStop-1] Root WebApplicationContext: initialization completed in 2956 ms
2020-05-12 10:46:19,954 INFO org.springframework.boot.web.servlet.FilterRegistrationBean [localhost-startStop-1] Mapping filter: 'characterEncodingFilter' to: [/*]
2020-05-12 10:46:19,954 INFO org.springframework.boot.web.servlet.FilterRegistrationBean [localhost-startStop-1] Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2020-05-12 10:46:19,955 INFO org.springframework.boot.web.servlet.FilterRegistrationBean [localhost-startStop-1] Mapping filter: 'httpPutFormContentFilter' to: [/*]
2020-05-12 10:46:19,955 INFO org.springframework.boot.web.servlet.FilterRegistrationBean [localhost-startStop-1] Mapping filter: 'requestContextFilter' to: [/*]
2020-05-12 10:46:19,955 INFO org.springframework.boot.web.servlet.DelegatingFilterProxyRegistrationBean [localhost-startStop-1] Mapping filter: 'springSecurityFilterChain' to: [/*]
2020-05-12 10:46:19,955 INFO org.springframework.boot.web.servlet.FilterRegistrationBean [localhost-startStop-1] Mapping filter: 'httpTraceFilter' to: [/*]
2020-05-12 10:46:19,955 INFO org.springframework.boot.web.servlet.FilterRegistrationBean [localhost-startStop-1] Mapping filter: 'webMvcMetricsFilter' to: [/*]
2020-05-12 10:46:19,955 INFO org.springframework.boot.web.servlet.ServletRegistrationBean [localhost-startStop-1] Servlet dispatcherServlet mapped to [/]
2020-05-12 10:46:20,869 INFO za.co.absa.hyperdrive.trigger.api.rest.WebSecurityConfig$$EnhancerBySpringCGLIB$$10d3924c [main] Using inmemory authentication
2020-05-12 10:46:21,089 INFO org.springframework.security.web.DefaultSecurityFilterChain [main] Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@5f95f1e1, org.springframework.security.web.context.SecurityContextPersistenceFilter@4afbb6c2, org.springframework.security.web.header.HeaderWriterFilter@380e1909, org.springframework.security.web.csrf.CsrfFilter@7c2dfa2, org.springframework.security.web.authentication.logout.LogoutFilter@76464795, org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@5f2de715, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@6c6017b9, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@4fe64d23, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@672a1c62, org.springframework.security.web.session.SessionManagementFilter@95eb320, org.springframework.security.web.access.ExceptionTranslationFilter@57f847af, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@29fa6b65]
2020-05-12 10:46:21,106 INFO org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor [main] Initializing ExecutorService 
2020-05-12 10:46:21,111 INFO org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor [main] Initializing ExecutorService  'asyncExecutor'
2020-05-12 10:46:21,465 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter [main] Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@76ed1b7c: startup date [Tue May 12 10:46:16 SAST 2020]; root of context hierarchy
2020-05-12 10:46:21,558 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/admin/startManager],methods=[POST]}" onto public java.util.concurrent.CompletableFuture<java.lang.Object> za.co.absa.hyperdrive.trigger.api.rest.controllers.AdminController.startManager()
2020-05-12 10:46:21,559 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/admin/isManager],methods=[GET]}" onto public java.util.concurrent.CompletableFuture<java.lang.Object> za.co.absa.hyperdrive.trigger.api.rest.controllers.AdminController.isManagerRunning()
2020-05-12 10:46:21,559 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/admin/stopManager],methods=[POST]}" onto public java.util.concurrent.CompletableFuture<java.lang.Object> za.co.absa.hyperdrive.trigger.api.rest.controllers.AdminController.stopManager()
2020-05-12 10:46:21,560 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/dagRuns/search],methods=[POST]}" onto public java.util.concurrent.CompletableFuture<za.co.absa.hyperdrive.trigger.models.search.TableSearchResponse<za.co.absa.hyperdrive.trigger.models.dagRuns.DagRun>> za.co.absa.hyperdrive.trigger.api.rest.controllers.DagRunController.searchDagRuns(za.co.absa.hyperdrive.trigger.models.search.TableSearchRequest)
2020-05-12 10:46:21,561 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/jobInstances],methods=[GET]}" onto public java.util.concurrent.CompletableFuture<scala.collection.Seq<za.co.absa.hyperdrive.trigger.models.JobInstance>> za.co.absa.hyperdrive.trigger.api.rest.controllers.JobInstanceController.getJobInstances(long)
2020-05-12 10:46:21,561 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/user/info],methods=[GET]}" onto public za.co.absa.hyperdrive.trigger.models.UserInfo za.co.absa.hyperdrive.trigger.api.rest.controllers.UserInfoController.userInfo()
2020-05-12 10:46:21,562 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/util/quartzDetail],methods=[GET]}" onto public za.co.absa.hyperdrive.trigger.models.QuartzExpressionDetail za.co.absa.hyperdrive.trigger.api.rest.controllers.UtilController.getQuartzDetail(java.lang.String)
2020-05-12 10:46:21,567 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflow],methods=[PUT]}" onto public java.util.concurrent.CompletableFuture<java.lang.Object> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.createWorkflow(za.co.absa.hyperdrive.trigger.models.WorkflowJoined)
2020-05-12 10:46:21,567 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflow],methods=[GET]}" onto public java.util.concurrent.CompletableFuture<scala.Option<za.co.absa.hyperdrive.trigger.models.WorkflowJoined>> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.getWorkflow(long)
2020-05-12 10:46:21,568 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflows],methods=[GET]}" onto public java.util.concurrent.CompletableFuture<scala.collection.Seq<za.co.absa.hyperdrive.trigger.models.Workflow>> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.getWorkflows()
2020-05-12 10:46:21,568 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflowsByProjectName],methods=[GET]}" onto public java.util.concurrent.CompletableFuture<scala.collection.Seq<za.co.absa.hyperdrive.trigger.models.Workflow>> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.getWorkflowsByProjectName(java.lang.String)
2020-05-12 10:46:21,568 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflows],methods=[DELETE]}" onto public java.util.concurrent.CompletableFuture<java.lang.Object> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.deleteWorkflow(long)
2020-05-12 10:46:21,568 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflows],methods=[POST]}" onto public java.util.concurrent.CompletableFuture<java.lang.Object> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.updateWorkflow(za.co.absa.hyperdrive.trigger.models.WorkflowJoined)
2020-05-12 10:46:21,568 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflows/{id}/setActiveState],methods=[POST]}" onto public java.util.concurrent.CompletableFuture<java.lang.Object> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.updateWorkflowActiveState(long,za.co.absa.hyperdrive.trigger.models.WorkflowState)
2020-05-12 10:46:21,569 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflows/projectNames],methods=[GET]}" onto public java.util.concurrent.CompletableFuture<scala.collection.immutable.Set<java.lang.String>> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.getProjectNames()
2020-05-12 10:46:21,569 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflows/projects],methods=[GET]}" onto public java.util.concurrent.CompletableFuture<scala.collection.Seq<za.co.absa.hyperdrive.trigger.models.Project>> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.getProjects()
2020-05-12 10:46:21,569 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflows/projectsInfo],methods=[GET]}" onto public java.util.concurrent.CompletableFuture<scala.collection.Seq<za.co.absa.hyperdrive.trigger.models.ProjectInfo>> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.getProjectsInfo()
2020-05-12 10:46:21,569 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/workflow/run],methods=[PUT]}" onto public java.util.concurrent.CompletableFuture<java.lang.Object> za.co.absa.hyperdrive.trigger.api.rest.controllers.WorkflowController.runWorkflow(long)
2020-05-12 10:46:21,572 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2020-05-12 10:46:21,573 INFO org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping [main] Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2020-05-12 10:46:21,784 INFO org.springframework.web.servlet.handler.SimpleUrlHandlerMapping [main] Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2020-05-12 10:46:21,784 INFO org.springframework.web.servlet.handler.SimpleUrlHandlerMapping [main] Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2020-05-12 10:46:21,815 INFO org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver [main] Detected @ExceptionHandler methods in apiExceptionHandler
2020-05-12 10:46:21,847 INFO org.springframework.web.servlet.handler.SimpleUrlHandlerMapping [main] Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2020-05-12 10:46:21,873 INFO org.springframework.boot.autoconfigure.web.servlet.WelcomePageHandlerMapping [main] Adding welcome page: class path resource [ui/index.html]
2020-05-12 10:46:21,917 INFO org.springframework.ldap.core.support.AbstractContextSource [main] Property 'userDn' not set - anonymous context will be used for read-write operations
2020-05-12 10:46:22,147 INFO org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping [main] Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
2020-05-12 10:46:22,148 INFO org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping [main] Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
2020-05-12 10:46:22,149 INFO org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping [main] Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2020-05-12 10:46:22,273 INFO org.springframework.jmx.export.annotation.AnnotationMBeanExporter [main] Registering beans for JMX exposure on startup
2020-05-12 10:46:22,291 INFO org.apache.coyote.http11.Http11NioProtocol [main] Starting ProtocolHandler ["http-nio-7123"]
2020-05-12 10:46:22,315 INFO org.apache.tomcat.util.net.NioSelectorPool [main] Using a shared selector for servlet write/read
2020-05-12 10:46:22,393 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [main] Tomcat started on port(s): 7123 (http) with context path ''
2020-05-12 10:46:22,405 INFO scala.App$class [main] Started App.class in 6.633 seconds (JVM running for 7.59)
2020-05-12 10:46:22,462 INFO org.quartz.impl.StdSchedulerFactory [main] Using default implementation for ThreadExecutor
2020-05-12 10:46:22,484 INFO org.quartz.core.SchedulerSignalerImpl [main] Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2020-05-12 10:46:22,484 INFO org.quartz.core.QuartzScheduler [main] Quartz Scheduler v.2.3.2 created.
2020-05-12 10:46:22,485 INFO org.quartz.simpl.RAMJobStore [main] RAMJobStore initialized.
2020-05-12 10:46:22,486 INFO org.quartz.core.QuartzScheduler [main] Scheduler meta-data: Quartz Scheduler (v2.3.2) 'za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzSchedulerThreadPool' - with 0 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

2020-05-12 10:46:22,486 INFO org.quartz.impl.StdSchedulerFactory [main] Quartz scheduler 'za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzScheduler' initialized from an externally provided properties instance.
2020-05-12 10:46:22,486 INFO org.quartz.impl.StdSchedulerFactory [main] Quartz scheduler version: 2.3.2
2020-05-12 10:46:22,486 INFO za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzSchedulerManager$ [main] Starting Quartz Scheduler za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzScheduler now
2020-05-12 10:46:22,487 INFO org.quartz.core.QuartzScheduler [main] Scheduler za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzScheduler_$_NON_CLUSTERED started.
2020-05-12 10:46:22,490 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-1] Running manager heart beat.
2020-05-12 10:46:22,493 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-4-thread-1] Processing events. Sensors: Set()
2020-05-12 10:46:22,540 INFO com.zaxxer.hikari.HikariDataSource [pool-4-thread-1] db - Starting...
2020-05-12 10:46:22,553 INFO com.zaxxer.hikari.HikariDataSource [pool-4-thread-1] db - Start completed.
2020-05-12 10:46:23,061 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-4] Running enqueue finished successfully.
2020-05-12 10:46:23,293 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8be54bb8-aae0-4d75-82b5-3f7a0e847d33
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:23,902 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:24,527 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,104 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,116 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#9).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,117 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 95ca362d-7064-492b-8d1e-69aa0c985674
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,117 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:25,118 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,118 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,118 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#6).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,119 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 912fda78-9c53-43b5-958a-485de1be5315
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,120 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:25,120 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,120 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,121 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#7).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,121 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 462d583c-43f3-4f5c-a203-7dc4c42e395a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,122 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:25,122 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,122 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,122 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#8).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,123 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2476713f-5eeb-4caf-ba19-7033fd505aeb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,124 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:25,124 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,124 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,124 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#5).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,125 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 65fbd186-5d2a-498f-bc9a-f8606b482ebf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,126 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:25,126 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,126 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,126 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#3).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,127 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 844b19bf-a75b-4a41-b6c3-53781c65469f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,128 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:25,128 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,128 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,129 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#32).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,131 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = aac53319-64b8-41d2-9f28-0802ab8082d4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,132 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:25,132 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,132 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,133 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#33).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,133 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = be1ac3aa-4109-431f-8227-a91f6eab72cc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,134 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:25,134 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,134 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,134 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#31).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,135 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [http://22.241.27.91:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ab5f59ae-4746-4a45-ab7b-1a8039f56ef8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,543 INFO org.apache.kafka.common.utils.AppInfoParser [pool-2-thread-3] Kafka version: 2.2.0
2020-05-12 10:46:25,543 INFO org.apache.kafka.common.utils.AppInfoParser [pool-2-thread-3] Kafka commitId: 05fcfde8f69b0349
2020-05-12 10:46:25,547 INFO org.apache.kafka.clients.consumer.KafkaConsumer [pool-2-thread-3] [Consumer clientId=consumer-10, groupId=ab5f59ae-4746-4a45-ab7b-1a8039f56ef8] Subscribed to topic(s): global.hyperdrive.za.notification.func
2020-05-12 10:46:25,556 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-3] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 875e64dc-175a-459e-aef8-60429dbef101
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:25,558 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:25,558 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:25,559 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-3] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:25,559 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-3] Couldn't create Kafka sensor for sensor (#42).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:25,568 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-4] Sensor id = 39.. Pooling new events.
2020-05-12 10:46:26,106 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-7] Sensor id = 39.. Messages received = List()
2020-05-12 10:46:26,110 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-10] Sensor id = 39.. Pooling successful
2020-05-12 10:46:26,110 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-5] Running sensors finished successfully.
2020-05-12 10:46:26,111 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-12] Processing events successful
2020-05-12 10:46:27,979 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-1] Running manager heart beat.
2020-05-12 10:46:27,980 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-4-thread-1] Processing events. Sensors: Set(39)
2020-05-12 10:46:28,003 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-8] Running enqueue finished successfully.
2020-05-12 10:46:28,007 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4345943e-4913-46b3-92f1-3ccd23a97942
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,008 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,008 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,008 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,008 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#9).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,011 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fb233c27-84a9-4859-ad56-489c08f856e3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,012 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,012 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,012 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,012 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#6).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,013 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a9ddf9c2-e55e-48d5-95ef-08e788d9d8db
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,013 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,014 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,014 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,014 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#7).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,015 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ab3d94e2-eedb-471f-8cc7-84dea1bc0feb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,015 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,015 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,015 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,016 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#8).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,016 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0519a395-47f1-4609-9607-e2d7f5b12f9f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,017 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,017 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,017 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,017 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#5).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,018 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 12fcad5d-5c0f-4d7b-bb2f-ab52c29c71f3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,018 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,018 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,018 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,018 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#3).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,019 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d69d2d52-b359-4edf-8a4e-4856de3f8cc1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,020 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,021 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,021 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,021 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#32).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,022 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c7e3bfc3-e912-459e-9b7e-6ab88fd3c4e4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,022 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,022 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,022 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,023 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#33).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,023 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7b7cdd78-92bf-4a35-90b8-2d103551c7aa
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,024 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,024 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,024 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,024 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#31).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,025 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-15] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e42cfc2e-bc37-42ba-bfd9-992bc8ac756e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:28,026 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:28,026 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:28,026 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-15] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:28,026 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-15] Couldn't create Kafka sensor for sensor (#42).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:28,027 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-16] Sensor id = 39.. Pooling new events.
2020-05-12 10:46:28,532 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-19] Sensor id = 39.. Messages received = List()
2020-05-12 10:46:28,533 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-1] Sensor id = 39.. Pooling successful
2020-05-12 10:46:28,533 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-20] Processing events successful
2020-05-12 10:46:28,533 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-9] Running sensors finished successfully.
2020-05-12 10:46:30,081 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-7123-exec-1] Initializing Spring FrameworkServlet 'dispatcherServlet'
2020-05-12 10:46:30,082 INFO org.springframework.web.servlet.DispatcherServlet [http-nio-7123-exec-1] FrameworkServlet 'dispatcherServlet': initialization started
2020-05-12 10:46:30,105 INFO org.springframework.web.servlet.DispatcherServlet [http-nio-7123-exec-1] FrameworkServlet 'dispatcherServlet': initialization completed in 23 ms
2020-05-12 10:46:33,004 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-1] Running manager heart beat.
2020-05-12 10:46:33,004 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-4-thread-1] Processing events. Sensors: Set(39)
2020-05-12 10:46:33,017 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-12] Running enqueue finished successfully.
2020-05-12 10:46:33,022 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d13695b2-1c49-4320-b181-1917ff578486
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,022 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,022 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,022 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,023 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#9).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,023 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 114396f8-52d6-499e-8544-391d7a8eb391
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,024 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,024 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,024 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,024 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#6).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,025 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a59820ac-d7dd-48c9-acfe-f920cb2e6b6d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,025 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,025 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,025 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,025 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#7).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,026 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d984f588-eae0-4f2c-8a34-d4f844b60b97
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,026 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,026 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,027 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,027 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#8).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,027 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2e0dc7c7-5645-4593-a746-dd9372d67810
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,028 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,028 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,028 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,028 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#5).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,028 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 258e8fbb-4445-443a-abaa-d813fc0e4c29
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,029 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,029 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,029 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,029 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#3).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,029 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f77f1d83-84b1-485f-ba50-6a1f0aae2174
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,030 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,030 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,030 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,030 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#32).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,030 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 014ada74-47b1-4189-9175-a3c1a90b7a8e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,031 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,031 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,031 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,031 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#33).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,032 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 22dbbb81-e8a0-428e-80ac-92c28c3582a6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,032 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,032 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,032 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,032 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#31).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,033 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-7] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 73a5c5fd-1bdb-40f1-a1d9-038c26bb8b80
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:33,033 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:33,033 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:33,033 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-7] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:33,033 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-7] Couldn't create Kafka sensor for sensor (#42).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:33,034 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-7] Sensor id = 39.. Pooling new events.
2020-05-12 10:46:33,538 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-9] Sensor id = 39.. Messages received = List()
2020-05-12 10:46:33,539 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-13] Sensor id = 39.. Pooling successful
2020-05-12 10:46:33,539 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-14] Processing events successful
2020-05-12 10:46:33,539 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-13] Running sensors finished successfully.
2020-05-12 10:46:38,019 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-1] Running manager heart beat.
2020-05-12 10:46:38,019 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-4-thread-1] Processing events. Sensors: Set(39)
2020-05-12 10:46:38,033 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-16] Running enqueue finished successfully.
2020-05-12 10:46:38,037 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 53343bf2-be7f-481e-bfb1-f58524006593
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,038 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,039 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,040 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,040 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#9).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,041 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4adcaeae-ec3e-4f81-9609-42806b27792a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,041 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,041 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,042 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,042 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#6).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,042 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8da2e9e3-72f2-4e47-ad86-ebe49187f279
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,043 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,043 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,043 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,043 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#7).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,044 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3baa7f74-0734-4d6b-902e-e05908275680
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,044 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,044 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,044 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,044 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#8).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,045 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c4674937-3e5b-413a-9c14-35291f9f6366
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,045 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,045 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,045 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,045 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#5).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,046 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 99db0bdc-f42b-48fd-b975-c87f78c51c3e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,046 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,046 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,046 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,047 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#3).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,047 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 835566b8-865d-4e8f-b91c-f5d42ecac74b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,048 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,048 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,048 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,048 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#32).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,049 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3651784e-699c-445c-8344-86cccdd509a9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,049 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,049 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,049 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,049 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#33).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,050 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 78dd03d3-32ac-47bc-b5ab-a1e8ae68a02f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,050 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,050 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,050 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,050 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#31).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,051 INFO org.apache.kafka.clients.consumer.ConsumerConfig [pool-2-thread-19] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [https://zadalnrapp1013.corp.dsarena.com:9093, https://zadalnrapp1014.corp.dsarena.com:9093, https://zadalnrapp1015.corp.dsarena.com:9093]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f023c446-503a-47bb-9d29-7d43be0326e6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 3
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-05-12 10:46:38,051 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1013.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1013.corp.dsarena.com
2020-05-12 10:46:38,051 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1014.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1014.corp.dsarena.com
2020-05-12 10:46:38,051 WARN org.apache.kafka.clients.ClientUtils [pool-2-thread-19] Couldn't resolve server https://zadalnrapp1015.corp.dsarena.com:9093 from bootstrap.servers as DNS resolution failed for zadalnrapp1015.corp.dsarena.com
2020-05-12 10:46:38,052 ERROR za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-19] Couldn't create Kafka sensor for sensor (#42).
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:811)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:659)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:639)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor.<init>(KafkaSensor.scala:44)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5$$anonfun$2.apply(Sensors.scala:91)
	at scala.util.Try$.apply(Try.scala:192)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:91)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1$$anonfun$apply$5.apply(Sensors.scala:88)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors$$anonfun$za$co$absa$hyperdrive$trigger$scheduler$sensors$Sensors$$addNewSensors$1.apply(Sensors.scala:88)
	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Success.map(Try.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:90)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:49)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:721)
	... 23 common frames omitted
2020-05-12 10:46:38,052 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-19] Sensor id = 39.. Pooling new events.
2020-05-12 10:46:38,553 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-1] Sensor id = 39.. Messages received = List()
2020-05-12 10:46:38,554 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.kafka.KafkaSensor [pool-2-thread-5] Sensor id = 39.. Pooling successful
2020-05-12 10:46:38,554 DEBUG za.co.absa.hyperdrive.trigger.scheduler.sensors.Sensors [pool-2-thread-1] Processing events successful
2020-05-12 10:46:38,554 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-17] Running sensors finished successfully.
2020-05-12 10:46:40,099 INFO org.apache.kafka.clients.consumer.KafkaConsumer [http-nio-7123-exec-2] [Consumer clientId=consumer-10, groupId=ab5f59ae-4746-4a45-ab7b-1a8039f56ef8] Unsubscribed all topics or patterns and assigned partitions
2020-05-12 10:46:40,100 INFO za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzSchedulerManager$ [http-nio-7123-exec-2] Stopping Quartz Scheduler za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzScheduler now
2020-05-12 10:46:40,100 INFO org.quartz.core.QuartzScheduler [http-nio-7123-exec-2] Scheduler za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzScheduler_$_NON_CLUSTERED paused.
2020-05-12 10:46:40,100 INFO za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzSchedulerManager$ [http-nio-7123-exec-2] Stopped Quartz Scheduler za.co.absa.hyperdrive.trigger.scheduler.sensors.time.TimeSensorQuartzScheduler
2020-05-12 10:46:43,039 DEBUG za.co.absa.hyperdrive.trigger.scheduler.JobScheduler [pool-4-thread-18] Manager stopped.
